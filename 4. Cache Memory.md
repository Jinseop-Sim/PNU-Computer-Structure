# Cache Memory
---
## Cache란?
> Cache Memory는 기존 Main Memory의 더딘 속도 증가를 돕기 위해 고안된 보조 Memory이다.  

## Cache Capacity
- Words 또는 Bytes 단위로 표현된다.
- 1 Byte = 8 Bits
- Word Size
  - Organization의 기본 단위이다.
  - 8, 16, 32bit가 보통 크기이며 크게는 64bit까지도 있다.

### Transfer Unit
- Internal : Data Bus Width에 따라 전송된다.
- External : Word보다 큰 단위인 Block에 따라 전송된다.

### Addressable Unit
- Address로 사용될 수 있는 가장 작은 Location
- Word 또는 Byte 크기를 사용한다.
  - A = Adress의 길이(bit)
  - N = Addressable Unit의 갯수
  - N = 2^A 가 된다.
  - 예를 들어 32bit Address길이를 가지면, 2^32개의 Addressable Unit이 사용가능하다.

## Memory Access Method
> Memory에 있는 정보에 접근 하는 방법에 대해 알아보자.  
- Sequential
  - 각 Data는 고유 주소를 갖지 않는다.
  - 시작부터 끝까지 순서에 따라 Data를 읽게 된다. (Rewind도 가능)
  - Access time은 이전 Data의 Location과 읽으려는 Data의 위치에 영향을 받는다.
  - ex) Tape
- Direct
  - 각 Data는 이제부터 고유 위치를 갖는다.
  - 각 Sector들을 Jump로 넘어다니며, 각 Track을 Sequential하게 찾는다.
  - Access time은 이전 Data의 Location과 읽으려는 Data의 위치에 영향을 받는다.
  - ex) Disk
- Associative
  - 각 Data는 주소에 따라 명확하게 구별이 되어 있다.
  - Location들은 Random하게 주소가 배정되며, 직접적인 접근이 가능하다.
  - 따라서 Access Time은 이전 접근이나 위치에 영향을 받지 않는다.
  - ex) RAM

## Performace
- Access Time
  - Address를 찾는 동작을 시작으로 Data를 획득하기까지 걸리는 시간이다.
  - RAM의 경우, Data의 주소에 접근해서 Transfer이 완료되는 시점까지가 Access Time이다.
  - non-RAM의 경우, 원하는 위치에 Hardware을 위치시키는 것 까지가 Access Time이다.
- Memory Cycle Time
  - RAM에서 굉장히 중요하게 적용된다.
  - 다음 접근을 하기 전에 __Recover__ 하는 시간이 필요하다.
  - 따라서 Cycle Time = Access time + Recover time이 된다.
- Transfer Rate
  - Memory에서 Data가 in/out 될 때 전송되는 Data의 양을 말한다.
  - RAM은 보통 1/(Memory Cycle Time)bps 로 계산한다.
  - non-RAM은 보통 Tn = Ta + N/R 로 계산한다.
    - Tn : Average time to R/W N bits
    - Ta : Average Access Time
    - N : # of bits

## Physical Types
- Semiconductor(반도체) : RAM, ROM, Flash Memory..
- Magnetic(자기) : Disk, Tape(사장)
- Optical(광학) : CD, DVD, Blue Ray

### Physical Characteristics
- Decay(부패) : 물리적으로 녹슬거나 손상을 입는 매체인가?
- Volatility(휘발성) : 전기 신호가 꺼지면 기억이 지워지는가? (중요)
- Erasabiltiy : Readonly(ROM, Optical)인가? Read/Writable 한가?
- Power consumption : 전력 소비

## Memory Hierarchy
> Memory를 설계할 때 우리느 어떤 것을 고려하는가?  

- 결국 우리가 원하는 것은 Performance의 증가이다!
  - 빠른 Access Time ==> Cost가 비싸진다.
  - 큰 용량 ==> Cost가 싸진다. 하지만 Access Time이 길어진다.
  - 이 둘은 Trade-off 관계에 있어 항상 딜레마이다.
  - 따라서 우리는 Memory Hierarhcy를 생각하며, 어떻게 하면 두 마리 토끼를 잡을 수 있을지 고민해야 한다.  
  ![image](https://user-images.githubusercontent.com/71700079/161678732-3d2ac8bc-2105-4c7e-8845-141bb2c84ee5.png)  

### Locality of Reference
> 공간 및 시간적 지역성을 확보해서 Memory의 Average Access Time을 줄일 수 있다.  

- Spatial Locality
  - 접근했던 곳 주변의 Data들에 접근하려는 지역성.
  - 균일하게 모든 위치를 참조하는 것이 아닌, 특정 Cluster 형태의 부분만 집중적으로 참조하려는 경향.
  - ex) Sequential Instruction Access, Arrays, Tables
- Temporal Locality
  - 최근에 접근했던 Data들에 다시 접근하려는 지역성.
  - ex) Iteration Loop

### Hierarchy List
- __Register(CPU) > L1 Cache > L2 Cache > Main Memory > Disk Cache > Disk(virtual memory)__
- 보통은 Disk까지가 마지막이다. 그 이후에 Optical.. Tape..가 부가적으로 붙을 수 있다.  

### Performance Example
> 2단계로 이루어진 Memory System이 있다고 가정을 하고, 성능 계산을 해보자.  

- Level 1 : Access Time T1(L1 Cache)
- Level 2 : Access Time T2(L2 Cache)
  - 이 때, Hit Ratio(H) : T1에서 Reference까 끝날 확률. (opp. Miss Ratio)
  - Average Access Time = L1에서 끝날 확률 * T1 + L1에서 끝나지 않을 확률 * (T1+T2) = H * T1 + (1-H) * (T1+T2)  
                        = T1 + (1 - H)T2  
- 직접 숫자에 대입해서 계산을 해보자.
- Level 1 : 1 microsecs
- Level 2 : 10 microsecs
  - 이 때, Hit Ratio(H) : 95%라고 가정하자.
  - Average Access Time = 0.95 * 1microsecs + 0.05 * (1 + 10) = 1 + 0.05 * 10 = 1.5 microsecs  

### DRAM & SRAM
- 보통은 DRAM이 상용화가 되어있다.
  - 하지만 SRAM이 DRAM보다 10배 가량 빨라서, 보통 Cache의 용도로 사용한다.
    - CPU <=> SRAM(L1) <=> DRAM(Main Memory)
  - 그럼 SRAM을 Main Memory로 쓰면 안되나요?
    - 안된다! DRAM보다 100배 가량 비싸기 때문에, 우리는 쓸 수 없다.

## Cache/Main Memory Structure  
![image](https://user-images.githubusercontent.com/71700079/161680622-1d1dcb2f-a5d7-4763-98be-ac13e09bea68.png)  
- 위와 같은 구조로 CPU와 Memory간의 Data 교환이 일어난다.  
- 아래와 같은 알고리즘에 따라 Cache와 Main Memory에 접근한다.  
![image](https://user-images.githubusercontent.com/71700079/161680767-7707b17a-4c3b-46fe-ad8d-f26968be7b2f.png)  

### Cache/Main Memory Design
- Memory
  - n bits Address를 갖는다.(2^n개의 Addressable Unit)
  - M fixed length의 Block들이 있고, 한 Block에 K개의 Words로 구성된다.
  - 이 때 Block의 길이 M = 2^n / K가 된다.
- Cache
  - C개의 Slots(Lines)로 구성된다. (Memory의 Block과 같은 개념이다.)
  - 따라서 한 개의 Slot은 K개의 Words로 구성되어 있다.
  - Slots의 수 C는 Memory Block의 길이 M보다 월등히 작다. (C << M)  
![image](https://user-images.githubusercontent.com/71700079/161681815-d860b516-8699-40c6-82c3-c96c1af595cf.png)  

### Cache Design(Cont'd)
- 보통 1K ~ 512K까지 용량이 존재한다.
- 당연히 용량이 커질 수록 더 비싸진다.
- Mapping Function
  - Direct : 지정된 위치에 저장을 한다. (Simple, 하지만 성능이 낮다.)
  - Associate : 아무데나 Random하게 저장한다. (Complex, 하지만 높은 성능을 보인다.)
  - Set Associate : 둘을 절충한 방식. (현재 가장 많이 쓰이는 방식.)

#### Direct Function Example  
![image](https://user-images.githubusercontent.com/71700079/161682387-af267498-16eb-4b88-987e-758e0af1c125.png)  

#### Associate Function Example

#### Set Associate Function Example
